{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"cnn_CIFAR","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN5/qkFbQGVFyuGcoHzZ/Yl"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Tr45ZSuZjd7","outputId":"0c3b8852-8742-4e7d-a8ac-b784e58ae14b"},"source":["\n","import numpy as np\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1  = nn.Sequential (\n","            # 32-3+1=30*30*32\n","            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(inplace=True),\n","            # 15 * 15 * 32\n","            nn.MaxPool2d(2,2)\n","        ) \n","\n","        self.conv2 = nn.Sequential (\n","            # 15-3+1=13*13*64\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","        self.conv3 = nn.Sequential (\n","            # 13-4+1=10*10*128\n","            nn.Conv2d(in_channels=64,out_channels=128, kernel_size=4),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(p=0.05),\n","            # 5 * 5 * 128 \n","            nn.MaxPool2d(2,2)\n","        )\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(3200, 1024),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(1024,512),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(512,128),\n","            nn.Dropout(0.05),\n","            nn.Linear(128,10)\n","        )\n","\n","    def forward(self, x):\n","        x = x.cuda()\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = x.view(x.shape[0],-1)\n","        x = self.fc(x)\n","        return x\n","\n","PATH = './model.pth'\n","\n","def main():\n","    batch_size, num_epoch, lr = 64,15,0.001\n","    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","    print(device)\n","    # load and transform dataset\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                            download=True, transform=transform)\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                            shuffle=True, num_workers=2)\n","\n","    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                        download=True, transform=transform)\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                            shuffle=False, num_workers=2)\n","\n","    classes = ('plane', 'car', 'bird', 'cat',\n","            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","    net = CNN()\n","    net.to(device)\n","   \n","    criterion = nn.CrossEntropyLoss().to(device)\n","    optimizer = optim.Adam(net.parameters(), lr=lr)\n","    # torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n","    # scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n","\n","    # optimizer = optim.SGD(net.parameters(), lr=0.0005, momentum=0.9)\n","    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n","\n","    for epoch in range(num_epoch):  # loop over the dataset multiple times\n","        for param_group in optimizer.param_groups:\n","            print(\"Epoch {}, learning rate: {}\".format(epoch, param_group['lr']))\n","        scheduler.step(epoch)\n","\n","        running_loss = 0.0\n","        \n","        for i, data in enumerate(trainloader, 0):\n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data[0].to(device), data[1].to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print statistics\n","            running_loss += loss.item()\n","            if i % 1000 == 999:    # print every 2000 mini-batches\n","                print('[%d, %5d] loss: %.3f' %\n","                    (epoch + 1, i + 1, running_loss / 2000))\n","                running_loss = 0.0\n","\n","    print('Finished Training')\n","\n","    torch.save(net.state_dict(), PATH)\n","\n","\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data[0].to(device), data[1].to(device)\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    print('Accuracy of the network on the 10000 test images: %d %%' % (\n","        100 * correct / total))\n","\n","           \n","if __name__ == \"__main__\":\n","    main()\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Epoch 0, learning rate: 0.001\n","Epoch 1, learning rate: 0.001\n","Epoch 2, learning rate: 0.001\n","Epoch 3, learning rate: 0.001\n","Epoch 4, learning rate: 0.001\n","Epoch 5, learning rate: 0.001\n","Epoch 6, learning rate: 0.001\n","Epoch 7, learning rate: 0.001\n","Epoch 8, learning rate: 0.001\n","Epoch 9, learning rate: 0.001\n","Epoch 10, learning rate: 0.001\n","Epoch 11, learning rate: 0.001\n","Epoch 12, learning rate: 0.0001\n","Epoch 13, learning rate: 0.0001\n"],"name":"stdout"}]}]}